\epigraph{The person who gave us this book told us that the book describes a
  secret technology called a database.\\
  We hear that the database is a system that allows everyone to share, manage,
  and use data.}{\textit{The King of Kod, from~\cite[p.~6]{takahashi_2009_manga_tmgtd}}}

If you want to save data, you need a database. And almost every computer program
needs to save some form of data, consequently requiring them to use a database.
The trend is also going towards generating more and more data, putting higher
strain on databases and requiring better performance. To improve and develop
databases is therefore a topic of much relevance in today's society.

One key component of databases is the query optimizer, the part of the database
that analyses the user's query and finds the optimal path to access it. Or
rather, theoretically it finds the optimal path. Work has been done on improving
query optimizers since the early '70s~\cite{chaudhuri_1998_overview_aooqoirs},
yet optimizers often select a bad access path, causing slow
queries~\cite{leis_2015_how_hgaqor}.

Guy Lohman identifies the cardinality estimate of the data to be main cause for bad plans:

\textit{``The root of all evil, the Achilles Heel of query optimization, is the
  estimation of the size of intermediate results, known as cardinalities''}

The estimates can often be wrong by several orders of
magnitude~\cite{lohman_query_iqoap}. These incorrect estimates then propagate
through the query and grow at an exponential
rate~\cite{ioannidis_1991_propagation_otpoeitsojr}, making the query optimizer
base its decisions on false grounds.

The topic of improving the estimations has seen some study, yet the evaluation
of new methods is often done on data that is easy to estimate, being uniformly
distributed. It is only recently that a study has been done to analyze the
performance of the optimizer end-to-end on complex real-world
data~\cite{leis_2015_how_hgaqor}. As one of the results, the study found that
PostgreSQL's optimizer performs unnaturally well on the typically tested uniform
data.

This thesis will aim to provide further insight into performance of
query optimizers by studying a previously unstudied metric and analysing the
performance of state-of-the-art optimizers. The evaluation will be conducted on
complex real-world data.

\section{Problem statement}
In this thesis two open-source state-of-the-art databases are evaluated:
MariaDB~\cite{mariadb_m} and PostgreSQL~\cite{postgresql_ptwmaosd}. One
real-world dataset containing a large amount of data and with a complex schema
and setup will be used in the evaluation. The database will be analyzed to
measure the performance of the query optimizer in order to answer the question:

\textit{How much effect does the cardinality estimate have on the query optimizers
  selection of access method during the join enumeration?}

To evaluate this, tests will be done in order to identify a correlation between
the quality of the cost estimation and the number of different access methods
used. To simulate a varying, but realistic, quality of the cost estimation, the
sample size used to estimate the cardinality will be varied. For a more in-depth
description of how this evaluation is conducted, see Section~\ref{sec:choiceofmethod}.

The exact setup and metrics of the dataset is described in
Section~\ref{sec:benchmark} and a motivation to why the databases are used is
described in Section~\ref{sec:choiceofdatabases}.

\section{Delimitation}
This thesis will do only one study and that is on the number of access methods.
Thus, no evaluation will be done on the performance of the databases in terms of
other metrics such as execution time. The reason is that the results found in
this thesis are generally applicable regardless of hardware and conditions under
which the evaluation is done. A study focusing on database performance is a much
larger undertaking and one that is beyond the scope of this thesis.

\section{Purpose}~\label{sec:purpose}
Query optimizers make bad cardinality estimates, and as a consequence bad cost
estimations of access paths~\cite{leis_2015_how_hgaqor} – but how much does this
affect the actual selection of access method? Even though the errors may be large,
they may not be sufficiently large to actually cause the optimizer to generate
different access paths.

There are three steps to the optimization – search space expansion, cost
estimation and join enumeration (more about those in Section~\ref{sec:queryopt})
– this thesis will focus on measuring what effect bad performance in the first
two steps has on the third and final one. The focus of the study will be to
identify if cost estimation does affect the access methods used and if the
behavior differs between the databases evaluated. Finding an answer to these two
will give a good indication to what effect the cost estimation has on the final
step in terms of access methods used.

Studying this is of relevance for the following reasons:
\begin{enumerate}
\item\label{item:purpose:tool} The tool developed for evaluation can be used
  in the future to measure the performance of query optimizers;
\item\label{item:purpose:steps} The evaluation will provide insight into
  what steps in the optimization process produce bad access paths;
\item\label{item:purpose:data} The performance of query optimizers has not
  seen much study using actual real-world data;
\item\label{item:purpose:performance} The actual performance of the
  databases right now will be evident;
\item\label{item:purpose:compare} Since both databases compared are
  open-source, one performing better may guide development for the other.
\end{enumerate}

Of primary interest for academia are probably
reasons~\ref{item:purpose:tool},~\ref{item:purpose:steps}
and~\ref{item:purpose:data} whereas database vendors might be more interested
in~\ref{item:purpose:performance} and~\ref{item:purpose:compare}.

\section{Ethics and sustainability}
There are no ethical implications of this thesis as an evaluation of a built-in
tool in databases has very few ethical implications.

When it comes to sustainability it is the case that any improvement to databases
will potentially provide considerable energy-savings considering the prevalence
and extensive use of databases.

\section{Outline}
Below is a brief outline of the chapters in the report and what can be expected
to be found in each:

\begin{itemize}
\item The \nameref{chap:introduction} chapter gives an introduction to the
  subject, the problem statement discussed, the purpose of
  the thesis and why it is novel and relevant.
\item The \nameref{chap:relatedwork} chapter contains an overview of what
  previous and relevant work has been done in the area of improving and
  evaluating the performance of query optimizers.
\item The \nameref{chap:theory} chapter gives a background and the information
  necessary to understand the thesis. The chapter focuses on providing the
  theory behind query optimization and related topics such as indexes.
\item The \nameref{chap:method} chapter provides a motivation to the choice of
  method as well as the dataset and query used. The chapter further provides
  implementation details for the tool developed and information on the options
  used for the evaluation done.
\item The \nameref{chap:results} chapter displays the results from the
  performance test in the form of graphs. It also gives some brief commentary on
  them.
\item The \nameref{chap:discussion} chapter discusses the performance of the
  query optimizers and the consequences of it, as well as the validity of the
  results. It also answers the problem statement and provides suggestions for
  future research.
\item The \nameref{chap:conclusions} chapter finally provides a concluding
  remark as to what the study focused on, what was done and the conclusions
  derived.
\end{itemize}